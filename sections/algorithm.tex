\subsection{Representation and Fusion Procedure}
The representation of the object to be reconstructed makes use of multiple `subvolumes' each pertaining to some patch on the object surface. 
New subvolumes are started when a sufficient amount of new voxels have been allocated and have had data integrated. By ensuring overlap 
between the subvolumes, transformations between them can be found. Using the multiple volume approach allows for pose estimation in each 
volume such that pose estimation discrepancies between subvolumes can be detected and are indicative of pose estimation drift.

The proposed system is inspired by\cite{Kolev2006} in that the representation used for the shape of the object to be modelled is a set of volumes 
of probabilities and surface information. The probabilities are posteriors over a per voxel assignment to being either belonging to the object or not. 
In the proposed system this volume of posterior probabilities is built into with each frame, parallel to the fusion process in systems such 
as KinectFusion\cite{Newcombe2011} and InfiniTAM\cite{Prisacariu2014}.

At each frame a probability map is constructed based on the predictions of the model given the current frame. During the fusion process, this 
smaller volume is mapped in to as a source of voxel wise appearance probability information. The overall appearance based posterior for a given voxel 
$\psi \in \mathbf{\Psi}$ takes the following form:
\begin{equation}
\begin{split}
P(\psi \in \mathbf{\Phi} | \mathbf{\Omega}, \mathbf{p}) = \prod_{t=0}^{\infty} P(\psi_{t} \in \mathbf{\Phi}_{t} | \mathbf{\Omega}_{t}, \mathbf{p}_{t})
\end{split}
\end{equation}
where $\mathbf{\Psi}$ is the volume of voxels for which measurements are accumulated, $\mathbf{\Phi}$ 
is the volume of voxels pertaining to the object, $\mathbf{\Omega}$ is the current image observation and $\mathbf{p}$ is the currently tracked pose
The above encodes the probability of a voxel belonging to an object as the product of the instantaneous conditionals for observations at each time step. 
Note that in general $\mathbf{\Phi} \subset \mathbf{\Psi}$, and the use of $\mathbf{\Phi}$ in the above equation is an abuse of notation as in the above 
$\mathbf{\Phi}$ is a discretisation of the continuous $\mathbf{\Phi}$ in the probabilistic formulation that follows. Finally, note that a conditional 
independence assumption is made to aid computational tractability in the model.

\subsection{Probabilistic Formulation of Object Reconstruction}
As previously highlighted, central to the proposed system is a volume of posterior probabilities pertaining to a voxel wise membership of either the 
object set or the non object set. This allows one to formulate the full joint distribution over the object as the following Probabilistic 
Graphical Model:
\begin{figure}[h]
	\centering
	\includegraphics{graphical_models/pgm1.pdf}
	\caption{Probabilistic formulation of the object reconstruction pipeline.}
\end{figure}

Where $\mathbf{\Phi}$ is the shape to be reconstructed, $\mathbf{u}$ is the appearance model volume, $\mathbf{L}$ is the 
set of consistency constraints for each adjacent sub volume pair, $\mathbf{\Omega}$ is the set of RGBD image pixels and $\mathbf{p}$ the 
set of poses over time.

This gives rise to the following analytical formulation of the above distribution:

\begin{equation}
\begin{split}
P(\mathbf{\Phi}, \mathbf{\Omega}, \mathbf{p}, \mathbf{u}, \mathbf{L}) = 
\prod_{v \in \mathcal{V}}\prod_{(s, s') \in \mathcal{S}}P(\mathbf{\Phi}|\mathbf{u}_{v}, \mathbf{L}_{(s, s')}) 
\prod_{t=0}^{\infty}\prod_{p \in \mathcal{P}}\\
P(\mathbf{u_{v}}|\mathbf{\Omega}_{p, t}, \mathbf{p}_{t})
P(\mathbf{L}_{(s, s')}|\mathbf{\Omega}_{p, t}, \mathbf{p}_{t})
P(\mathbf{L}_{(s, s')})P(\mathbf{p}_{t})P(\mathbf{\Omega}_{p, t})
\end{split}
\end{equation}
where $\mathcal{V}$ is the set of voxels across all sub volumes, $\mathcal{P}$ is the set of RGBD pixels for a given 
frame and $\mathcal{S}$ is the set of sub volumes.

However, if one were to assume temporal and pixel wise independence in the RGBD observations and temporal independence in 
the poses, the plate containing $\mathbf{\Omega}$ and $\mathbf{p}$ can be removed:
\begin{equation}
\begin{split}
P(\mathbf{\Phi}, \mathbf{\Omega}, \mathbf{p}, \mathbf{u}, \mathbf{L}) = 
\prod_{v \in \mathcal{V}}P(\mathbf{\Phi}|\mathbf{u}_{v})
\prod_{(s, s') \in \mathcal{S}}P(\mathbf{u_{v}}|\mathbf{\Omega}, \mathbf{p}, \mathbf{L}_{(s, s')})\\
P(\mathbf{L}_{(s, s')}|\mathbf{\Omega}, \mathbf{p}) P(\mathbf{L}_{(s, s')})P(\mathbf{p})P(\mathbf{\Omega})
\end{split}
\end{equation}
In practice this temporal independence assumption causes no issues.

Furthermore, if one assumes voxel wise independence, the plate over voxels can be removed. Finally, assuming $P(\mathbf{p})$ and 
$P(\mathbf{\Omega})$ are uniform distributions, then we have the following, simpler distribution:
\begin{figure}[h]
	\centering
	\includegraphics{graphical_models/pgm2.pdf}
	\caption{Simplified probabilistic formulation of the object reconstruction pipeline.}
\end{figure}

With the following analytical form:
\begin{equation}
\begin{split}
P(\mathbf{\Phi}, \mathbf{\Omega}, \mathbf{p}, \mathbf{u}, \mathbf{L}) = 
\prod_{(s, s') \in \mathcal{S}} P(\mathbf{\Phi}|\mathbf{u}, \mathbf{L}_{(s, s')})
P(\mathbf{u}|\mathbf{\Omega}, \mathbf{p})\\
P(\mathbf{L}_{(s, s')}|\mathbf{\Omega}, \mathbf{p})
P(\mathbf{L}_{(s, s')})
\end{split}
\end{equation}

The above formalisms describe a probabilistic framework in which online corrections can be made to the reconstructed model to counteract 
errors incurred by pose tracking inconsistencies. As with previous dense SLAM systems \cite{Newcombe2011, Prisacariu2014, Neissner2013}, 
our system follows a pipeline that consists of a tracking stage and an integration stage. However, our formulation of this pipeline 
consists of an additional estimation module that relies on the use of a subvolume representation to correct tracking errors by applying 
transformations to the subsegments to align them when there are intra subsegment tracking inconsistencies. 
As previously described, during reconstruction the object is split in to subsegments, also referred to in a technical context as subvolumes, 
with the pose estimation performed in each of the active, visible subsegments. The pose estimation stage for each of these subsegments follows 
the standard ICP(Iterated Closest Point) approach.
As inference on the joint distribution of our model is intractable, conditional independence assumptions are made that do not appear 
to cause any functional issues. The estimation phase of the pipeline is described in the following section.

\subsection{Estimating Deformations}
The tracking consistency constraint denoted by the variable $\mathbf{L}$ in the above graphical model can be enforced in terms of minimising the 
transformations between adjacent submaps, such that the camera poses tracked in each subvolume are consistent.  The approach proposed in this work differs from \cite{Kahler2016} in that the optimisation is integrated in to the probabilistic 
formulation previously outlined. Given instantaneously inferred transforms between subvolumes obtained from tracking results, 
the objective is to infer a robust, consistent deformation transformation for the subvolume pair.

As such, for each pair of visible subvolumes $(s, s')$, the following posterior must be maximised:
\begin{equation}
\begin{split}
%Bayes rule + chain rule for P(omega, p)
P(\mathbf{\Omega}, \mathbf{p} | \mathbf{L}_{(s, s')}) = \frac{P(\mathbf{L}_{(s, s')} | \mathbf{\Omega}, \mathbf{p}) P(\mathbf{\Omega} | \mathbf{p})P(\mathbf{p})}
{P(\mathbf{L}_{(s, s')})}
\end{split}
\end{equation}
The intuition behind the above equation is that the deformation $\mathbf{L}_{(s, s')}$ applied to the probability field $\mathbf{u}$ should 
increase the probability of observing the current pose $\mathbf{p}$ given the current RGBD frame $\mathbf{\Omega}$ by reducing the 
variance of the camera tracking result. As such, global tracking variance is reduced by enforcing local consistency, improving the quality 
of the reconstruction.

The maximisation of the above posterior consists of a two stage process. Firstly, as a preprocessing step, the true transformation between 
subsegments is estimated over time from observed offsets, as documented in the following section. This inferred transformation is used to 
initialise a gradient based maximisation of the above posterior to yield an optimal deformation as the maximisation of the given posterior is 
a highly nonlinear optimisation problem. The intuition behind this schema is that the 
gradient based optimisation routine is used to refine the inferred transformations between subsegments, improving robustness.

It should be noted that in our implementation the $P(\mathbf{\Omega} | \mathbf{p})$ term is assumed to be uniform in the case of an 
RGBD sensor being used, however for applications such as monocular SLAM this term may be replaced with a noise model when there is 
significant uncertainty about the given depth map at each frame.

The following proportionality to the distribution over deformations is made:
\begin{equation}
\begin{split}
P(\mathbf{L}_{(s, s')} | \mathbf{\Omega}, \mathbf{p}) \propto P(\mathbf{\Psi}_{s}(\mathbf{x}) | \mathbf{\Psi}_{s'}(\Lambda(\mathbf{x})))
\end{split}
\end{equation}
With the likelihood function taking the following form(a Gaussian distribution is assumed):
\begin{equation}
\begin{split}
P(\mathbf{\Psi}_{s'}(\Lambda(\mathbf{x}))) = \prod_{(s, s') \in \mathcal{S}} \frac{1}{\sqrt{2 \pi \sigma}} \exp{\frac{-(\mathbf{\Psi}_{s}(\mathbf{x}) - \mathbf{\Psi}_{s'}(\Lambda(\mathbf{x})))^2}{2\sigma^2}}
\end{split}
\end{equation}
Or alternatively:-
\begin{equation}
\begin{split}
\ln P(\mathbf{\Psi}_{s'}(\Lambda(\mathbf{x}))) = m\ln\frac{1}{\sqrt{2\pi}\sigma}\\
-\frac{1}{2\sigma^2} \sum_{(s, s') \in \mathcal{S}} \bigg( \mathbf{\Psi}_{s}(\mathbf{x}) - \mathbf{\Psi}_{s'}(G(\mathbf{x})) \bigg)^2
\end{split}
\end{equation}
Where $\mathbf{\Psi}(.)$ is a scalar valued SDF(Signed Distance Function), a dicretised field of $\mathbf{\Phi}$, as previously described. $\mathbf{x}$ is a point represented by a 3-vector and $G(.)$ is a transformation function taking the following form:
\begin{equation}
\begin{split}
\Lambda(\mathbf{x}) = \mathbf{R}(r_{1}, r_{2}, r_{3})\mathbf{x} + \mathbf{t}
\end{split}
\end{equation}
Where $\mathbf{R}(.)$ is a rotation matrix from the Special Orthogonal group $\mathbbm{SO}(3)$ paramaterised by the three Modified 
Rodrigues Parameters\cite{Shuster1993} $r_{1}$, $r_{2}$ and $r_{3}$.

Note that the logarithmic form of the above likelihood is suitable to Nonlinear Least Squares optimisation, allowing the posterior of equation 4 
to be maximised in terms of the likelihood term of equation 4. To perform MLE(Maximum Likelihood Estimation) over this likelihood using 
an optimisation routine such as Levenberg Marquardt, the following gradients must be computed for the rotational component of the 
deformation:-
\begin{equation}
\begin{split}
\frac{\partial E}{\partial r_{n}} = \frac{\partial E}{\partial \mathbf{\Psi}} \frac{\partial \mathbf{\Psi}}{\partial \Lambda} \frac{\partial \Lambda}{\partial r_{n}} \text{for } n \in {1,2,3}
\end{split}
\end{equation}
Similarly for the translational component:-
\begin{equation}
\begin{split}
\frac{\partial E}{\partial \mathbf{t}_{d}} = \frac{\partial E}{\partial \mathbf{\Psi}} \frac{\partial \mathbf{\Psi}}{\partial \Lambda} \frac{\partial \Lambda}{\partial \mathbf{t}_{d}} \text{for } d \in {x,y,z}
\end{split}
\end{equation}

\iffalse
\subsection{Estimation of Intra-Subvolume Constraints}
Due to the on-line nature of the fusion pipeline there is a degree of uncertainty around the measured offsets between subvolumes. As such, to 
counter this and yield a robust starting constraint for the previously described optimisation procedure, a recursive bayesian estimation 
procedure is used to estimate the true pose difference between two subvolumes.

As such, the update for the starting deformation transformation $\mathbf{L}_{t}$ may be defined in 
terms of $\mathbf{L}_{t-1}$ and observed offsets transforms between segments $\mathbf{Z_{(s, s')}} = \mathbf{T}_{s}^{-1}\mathbf{T}_{s'}$  in a predict-update fashion, using the following prediction equation:
\begin{equation}
\begin{split}
P(\mathbf{L}_{i} | \mathbf{Z}_{1:i-1}) = \int P(\mathbf{L}_{i} | \mathbf{L}_{i-1})P(\mathbf{L}_{i-1} | \mathbf{Z}_{1:i-1}) d\mathbf{L}_{i-1}
\end{split}
\end{equation}
and update equation
\begin{equation}
\begin{split}
P(\mathbf{L}_{i} | \mathbf{Z}_{1:i}) = \frac{P(\mathbf{Z}_{i} | \mathbf{L}_{i})P(\mathbf{L}_{i} | \mathbf{Z}_{1:i-1})}{P(\mathbf{Z}_{i} | \mathbf{Z}_{1:i-1})}
\end{split}
\end{equation}
where
\begin{equation}
\begin{split}
P(\mathbf{Z}_{i} | \mathbf{Z}_{1:i-1}) = \int P(\mathbf{Z}_{i} | \mathbf{L}_{i})P(\mathbf{L}_{i} | \mathbf{Z}_{1:i-1}) d\mathbf{L}_{i}
\end{split}
\end{equation}
However, it should be noted that the denominator of the update equation may in practice be replaced with a normalisation constant as follows:
\begin{equation}
\begin{split}
P(\mathbf{L}_{i} | \mathbf{Z}_{1:i}) = \alpha P(\mathbf{Z}_{i} | \mathbf{L}_{i})P(\mathbf{L}_{i} | \mathbf{Z}_{1:i-1})
\end{split}
\end{equation}
Note that in the above equations, the constraint pair subscript has been dropped for clarity in notation.

This online prediction-update schema will allow the evolution of pose difference constraints over time increasing their robustness at the time 
of optimisation of deformations.

\fi

\section{Implicit Surface Deformations}
In the previous section, a model and estimation procedure was presented to find optimal transformations between the aforementioned subvolumes. When rendering 
however, the overall object surface $\mathbf{\Phi}$ is implicitly deformed by a combining functional $\mathbf{\zeta}(\mathbf{\Phi})$ over each of the subvolumes to which transformations have been applied.
As such the rendering of the surface $\mathbf{\Phi}$ is given by the following:
\begin{equation}
\begin{split}
\mathbf{\Phi} = \int_{\chi \in X} \mathbf{\zeta}(\mathbf{\Phi}_{\chi}) d \mathbf{\Phi}_{\chi}
\end{split}
\end{equation}
where $X$ is the set of subvolumes contributing to the surface $\mathbf{\Phi}$

\section{Volumetric Object Segmentation}
The final stage in the proposed object reconstruction pipeline is the segmentation of the object voxels from those that have had measurements fused 
from the background. This segmentation is formulated within a CRF framework, where each node in the CRF represents a set of neighbouring voxels in space, 
with connections being made between adjacent neighbourhoods. The process of segmentation can be posed as an energy minimisation problem over a cut in voxel space, 
such that a segmentation in 3D is yielded. The following energy functional consists of the unary posterior probabilities over appearance accumulated during the fusion 
process for a region in space and an additional pairwise smoothing term representing the physical appearance similarity of the object region represented by the voxel 
neighbourhoods $\gamma$ and $\gamma^{'}$:
\begin{equation}
\begin{split}
E_{n} = \prod_{t=0}^{\infty} \prod_{\psi \in \mathbf{\Phi}_{n}} P(\psi \in \mathbf{\Psi} | \mathbf{\Omega}_{t}, \mathbf{p}_{t}) + P(\mathbb{E}[\mathbf{c}]_{\gamma} | \mathbb{E}[\mathbf{c}]_{\gamma^{'}})
\end{split}
\end{equation}
where $\mathbf{c}$ represents the colour measurement fused in to a voxel, for all $N$ subvolumes.

\section{Implementation Notes}
The probabilities that are accumulated into the volume are generated from a Random Forest based appearance model using patch based features encompassing 
appearance and surface information, such as depth gradients, initialised prior to reconstruction by a user interaction in the first frame. There are two 
classes in the appearance model, one for the foreground object and one for the background, with the foreground object indicated by a bounding box on the 
first RGB frame.

An overview of the processing pipeline for the proposed system is outlined in Figure \ref{pipelineDiagram}.
\begin{figure*}[h]
	\centering
	\includegraphics[scale=0.5]{pipeline.pdf}
	\caption{Object reconstruction pipeline.}
	\label{pipelineDiagram}
\end{figure*}