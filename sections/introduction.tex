Dense SLAM (Simultaneous Localisation and Mapping) has proven to be an effective paradigm for the reconstruction of moderately-sized scenes,
with much of the recent research on the topic being driven by the availability of inexpensive, consumer-grade depth sensing equipment \cite{Newcombe2011,Niessner2013,Prisacariu2014}. 
However, a prominent problem within the dense SLAM literature is that of accurate pose estimation given potentially erroneous measurements, or a degree of measurement ambiguity. Many common approaches\cite{Besl1992,Levoy2001} to the problem exploit texture and/or geometry features of the scene to estimate an updated pose at each frame.

However, there are failure cases when there is a lack of geometric or texture-based features against which a system may track. 
%Purely geometry based approaches may fail with a lack of descriptive geometry, as may texture based approaches with a lack of texture. 

Common issues range from tracking drift, often caused by geometric and/or texture ambiguity, to complete tracker failure. In addition, many dense 
SLAM systems fail during loop closure events, with explicit handling often required. The error incurred during loop closure events can be detrimental 
to tracking quality in such systems.

\begin{figure}[!t]
	\centering
	\begin{tabular}{cccc}
		\bmvaHangBox{\fbox{\includegraphics[width=2.5cm]{screenshots/bear_colour.PNG}}}&
		\bmvaHangBox{\fbox{\includegraphics[width=2.5cm]{screenshots/chair_colour.PNG}}}&
		\bmvaHangBox{\fbox{\includegraphics[width=2.5cm]{screenshots/dino_colour.PNG}}}&
		\bmvaHangBox{\fbox{\includegraphics[width=2.5cm]{screenshots/rock_colour.PNG}}}\\
		(a)&(b)&(c)&(d)
	\end{tabular}
	\caption{
		\textbf{(a)} Reconstructed Teddy Bear.
		\textbf{(b)} Reconstructed Chair.
		\textbf{(c)} Reconstructed Dinosaur Head.
		\textbf{(d)} Reconstructed Rock.
	}
	%A person enters the static scene\textbf{(a)}, is detected as a dynamic object\textbf{(b)} and becomes stable\textbf{(c)}.}
	\label{fig:demo}
\end{figure}

Failure cases for such approaches are only exacerbated when there is less data to track with/against, as is the case with the tracking of an 
object's pose w.r.t.\ the camera (the inverse of the camera tracking problem). In the case of tracking an object's motion w.r.t.\ the static 
scene, only the object surface points are available for tracking.

As dense object reconstruction can be seen as a smaller-scale equivalent of the dense scene reconstruction problem, it too is prone to 
tracking drift and loop closure issues, sometimes to a prohibitive level. As previously highlighted, the tracking of an object's pose w.r.t.\ the camera 
is also affected by geometric or texture-based ambiguities, caused by a much more focused domain of the data available to the tracking algorithm. 
Such failure cases may occur with the presence of ambiguous features, and a lack of unambiguous features on the object surface, causing data 
association errors when attempting to recover pose.

For example, when reconstructing an entire scene and assuming no masking, all of the data in the current and previous frames is available for tracking. When tracking solely an object this is not the case as attempting to track an objects movement w.r.t.\ static scene points and dynamic object points would cause a failure event.

In this paper, we present a probabilistic object reconstruction framework for the reconstruction of rigid objects based on 
depth and texture features. The framework facilitates the correction of camera tracking drift by representing the object to be reconstructed as a
collection of overlapping subsegments such that transformations may be inferred to keep the subsegments aligned, resulting in a consistent
overall model. By combining these transformed surfaces, we extract an implicitly deformed surface, optimised for via the probabilistic formulation 
that follows.

We utilise a volumetric representation for each of these object subsegments, as with other larger-scale reconstruction
systems \cite{Kahler2016}. Each voxel in the subsegments has additional appearance posterior information pertaining to the voxel's membership 
of the object. Over time, multiple volumes containing both surface and probabilistic appearance information are maintained and manipulated to 
yield a robust and temporally-consistent model.

Finally, we optimise for the optimum object shape within a CRF (Conditional Random Field) framework.

We demonstrate efficacy in object reconstruction by performing online transformations to the aforementioned subsegments to counteract inconsistencies caused by drift in the object pose tracking process.

We perform quantitative and qualitative experiments and demonstrate efficacious pose estimation and reconstruction quality respectively. As a base 
for comparison, tracking quality is compared with a well established dense SLAM evaluation benchmark \cite{sturm12iros} and reconstruction quality 
with the object reconstruction system outlined in \cite{Ren2013}.

The motivation behind this work is to improve current semantic scene understanding\cite{Valentin2015, Golodetz2015} by providing a means to procure 
robust object models that can be learnt and recognised. This is a future direction for this and related works.