Dense SLAM (Simultaneous Localisation and Mapping) has proven to be an effective paradigm for the reconstruction of moderately-sized scenes,
with much recent research on the topic driven by the availability of inexpensive, consumer-grade depth sensing equipment \cite{Newcombe2011,Niessner2013,Prisacariu2014}. 
However, a prominent problem within the dense SLAM literature is that of accurate pose estimation given potentially erroneous measurements, or a degree of measurement ambiguity. Many common approaches to the problem exploit texture and/or geometry features of the scene to estimate 
an updated pose at each frame.

However, there are failure cases when there is a lack of geometrical or texture based features to which a system may track against. Purely geometry 
based approaches may fail with a lack of descriptive geometry, as may texture based approaches with a lack of texture. 

Common issues range from tracking drift, often caused by geometrical and/or texture ambiguity, to complete tracker failure. In addition, many dense 
SLAM systems fail during loop closure events with explicit handling often required. The error incurred during loop closure events can be detrimental 
to tracking quality in such systems. 

Failure cases for such approaches are only exacerbated when there is less data to track with/against, as is the case with the tracking of an 
object's pose w.r.t.\ the camera (the inverse of the camera tracking problem).

As dense object reconstruction can be seen as a smaller-scale equivalent of the scene-based dense reconstruction problem, it too is prone to the
tracking drift and loop closure issues, sometimes to a prohibitive level. As previously highlighted, the tracking of an object's pose w.r.t.\ the camera 
is also affected by geometric or texture-based ambiguities, caused by a much more focused domain of the data available to the tracking algorithm. 
Such failure cases may occur with a combination of ambiguous features on the object and a lack of unambiguous features as are often present 
in the scene based counterpart.

For example, when reconstructing an entire scene, all of the data in the current and previous frames is available for tracking. When tracking solely an object this is not the case as attempting to track an objects movement w.r.t.\ static scene points and dynamic object points would cause a failure 
event.

In this paper, we present a probabilistic object reconstruction framework for reconstruction of rigid objects based on 
appearances. The framework facilitates the correction of camera tracking drift by representing the object to be reconstructed as a
collection of overlapping subsegments such that transformations may be inferred to keep the subsegments aligned, resulting in a consistent
overall model. By combining these transformed surfaces we extract an implicitly deformed surface optimised for via the probabilistic formulation 
that follows.

We utilise a volumetric representation for each of these object subsegments, as with other larger-scale reconstruction
systems\cite{Kahler2016}. Each voxel in the subsegments has additional appearance posterior information pertaining to the voxel's membership 
of the object. Over time, multiple volumes containing both surface and probabilistic appearance information are maintained and manipulated to 
yield a robust and temporally-consistent model.

Finally, we optimise for the optimum object shape within a CRF(Conditional Random Field) framework.

We demonstrate an efficacy object reconstruction by performing online transformations to the aforementioned subsegments to counteract inconsistencies caused by drift in the object pose tracking process.

We perform quantitative and qualitative experiments and demonstrate efficacious pose estimation and reconstruction quality respectively. As a base 
for comparison tracking quality is compared with a well established dense SLAM system \cite{Prisacariu2014} and reconstruction quality with the 
object reconstruction system outlined in \cite{Ren2013}.