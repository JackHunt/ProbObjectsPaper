\paragraph{Dense 3D Reconstruction}

Much recent dense 3D reconstruction work stems back to the seminal KinectFusion work of Newcombe et al.\ \cite{Newcombe2011}. This was used to build an implicit, voxel-based TSDF representation \cite{Curless1996} of a small-scale environment, but could only reconstruct static scenes, and struggled to scale due to inefficient use of memory and difficulties in preventing significant tracking drift in larger-scale scenes. Scalability has progressively been addressed by a moving reconstruction window \cite{Roth2012,Whelan2012}, octrees \cite{Zeng2012}, and sparse methods based on voxel hashing and streaming data to and from the GPU \cite{Niessner2013,Prisacariu2014}. This has made it possible to reconstruct static scenes whose size is only limited by available system memory, although reconstructing a large scene can still occupy significant space. Tracking drift has also been addressed to some extent, generally by detecting loop closures and either rigidly or non-rigidly deforming parts of the scene \cite{Zhou2013,Whelan2015IJRR,Whelan2015RSS}. Other approaches exist that do not explicitly detect loop closures \cite{Fioraio2015}. Recently, Dai et al.\ \cite{dai2016bundlefusion} introduced a system that improves pose estimation for large-scale scenes by considering each previously seen frame within a hierarchical framework and performing sparse feature matching to optimise for the camera pose. However, mismatches between keypoints are reported to have an impact on the robustness of their optimisation procedure. K{\"a}hler et al.\ \cite{Kahler2016} took a different approach, showing how to combine a multi-segment representation of the scene with loop closure detection and an online model correction algorithm to achieve accurate, globally-consistent scene reconstruction. They reduce drift by tracking only against recent segments of the scene and adjusting the poses between segments online, before refining the final model using pose graph optimisation. In this paper, we extend this latter approach to achieve globally-consistent reconstructions of objects.


\iffalse
Much 3D reconstruction work in recent years has been influenced by the seminal KinectFusion work \cite{Newcombe2011} of Newcombe et al in which
RGBD data was integrated into a volumetric representation of the scene, performing simultaneous tracking and mapping. The end result was
high quality 3D static scene models. 
However, KinectFusion notably suffered from tracking drift, had no capacity to handle loop closure events, had an inability to handle dynamic scenes 
and had scalability issues.

There have been a number of works since to counter the scalability issues of \cite{Newcombe2011} with approaches including moving reconstruction 
windows \cite{Roth2012, Whelan2012}, Octree representations \cite{Zeng2012} and other sparse voxel methods \cite{Prisacariu2014, Chen2013}.

Following KinectFusion, Nie{\ss}ner et al present another volumetric reconstruction system \cite{Niessner2013} based around the notion of
hashing regions of space in to voxel blocks. The primary contribution is the ability to scale the abilities of KinectFusion to larger
scenes. However, the contributions do not extend to the camera tracking drift and loop closure problems.

Prisacariu et al present an alternative voxel hashing based system \cite{Prisacariu2014} which provides many optimisations and like \cite{Niessner2013}, an open source 
implementation. However, the limitations of \cite{Newcombe2011,Niessner2013} with regards to loop closure and tracking drift are still present. 
However, a later publication \cite{Kahler2016} from the authors of \cite{Prisacariu2014} presents a loop closure and tracking drift reduction 
solution based on the splitting of the scene in to sub scenes with pose adjustments made to tracking constraints between them, with 
a pose graph optimisation as a final processing step. This approach is extremely pertinent to this work as it inspired the multi subvolume approach 
that we take. Dai et al \cite{dai2016bundlefusion} recently introduced a system that improves pose estimation for large scale scenes by considering each previously seen 
frame within a hierarchical framework and perform sparse feature matching to optimise for the camera pose. Though it should be noted that mismatches between keypoints are 
reported to have an impact on the robustness of the optimisation procedure.

All of the aforementioned voxel based reconstruction works are closely related to and derived from the early work of Curless and Levoy \cite{Curless1996} 
which introduces the notion of encoding isosurfaces with TSDF's (Truncated Signed Distance Function). The isosurface is the zero level set of the function 
and at all other points within some truncation region, a distance to the zero level set.
\fi

\paragraph{Object Reconstruction}
In addition to scene-scale works, there has been much work on object reconstruction and object-centric SLAM. Kolev et al.\ \cite{Kolev2006} presented a probabilistic 3D segmentation and surface extraction algorithm based on a variational evolution of a level set representation, but did not handle loop closures and tested their approach only on images with no background noise. Weise et al.\ \cite{Weise2009} presented an explicit, surfel-based reconstruction system for objects rotating in front of a 3D range scanner. They maintain an object topology graph to handle loop closures online, but they only deform the object model when detecting loop closure events, whereas our approach continuously updates the rigid transformations between object segments, making it easier for the user to see what the final model will look like. Ohno et al.\ \cite{Ohno2011} presented a robotic system for reconstructing unknown objects in an environment by pushing them and estimating their motion using 3D flow. Krainin et al.\ \cite{Krainin2011IJRR} present another robotic system that uses Kalman filtering and articulated ICP to track both the robot's manipulator and the object. They perform loop closure in a similar way to \cite{Weise2009} and achieve very good surfel models of the object, but their approach requires specialist hardware. Cui et al.\ \cite{Cui2013} presented an object reconstruction system based on Time of Flight (ToF) sensors. They use a super-resolution representation of chunks of raw depth images to reconstruct detailed models. Mihalyi et al.\ \cite{Mihalyi2015} used augmented reality markers to make it possible for untrained users to achieve robust object reconstructions. Their approach works for a range of objects, but the need to add markers to the scene in advance is quite limiting in practice. Narayan et al.\ \cite{Narayan2015} combines KinectFusion with visual hull techniques to reconstruct objects with concavities and translucencies. Panteleris et al.\ \cite{Pantaleris2015, Panteleris2015b} reconstruct objects by tracking hand-object manipulations. Their approach runs in real time, but they do not handle loop closures. Tzionas and Gall \cite{Tzionas2015} also make use of hand-object interactions, presenting an elegant system that can reconstruct featureless and highly symmetric objects by tracking contact points between the hand and the object. Their system produces appealing results, but is not real-time and can fail if the fingers slip over the manipulated object. Gupta et al.\ \cite{Gupta2016} performed object reconstruction based on monocular, multi-view cues. They segment the objects using graph cuts and track based on geometric/texture cues, but do not handle loop closures and report fluctuating tracking quality caused by illumination variation and specular surfaces. Recently, Slavcheva et al.\ \cite{slavcheva2016eccv} presented an object reconstruction system that estimates poses by registering pairs of TSDF volumes. Their system handles loop closures and achieves high-quality results, but at the cost of relying on fiducial markers to improve their tracking and performing loop closure offline as a post-processing step.

The closest approach to ours is that of Ren et al.\ \cite{Ren2013}, who presented a probabilistic tracking and reconstruction system that reconstructs objects based on an appearance model, evolving a level set representation for voxels that are on the object. However, they do not detect loop closures and are prone to tracking drift. Their later work \cite{Ren2014} extended \cite{Ren2013} to track multiple objects for which an initial model is available in real time.

%The work however relies on the objects to be tracked having identical appearances, though this does indicate that the authors system is capable of distinguishing between objects of identical appearance.

\iffalse
Kolev et al present a probabilistic 3D segmentation and surface extraction algorithm \cite{Kolev2006} based on a variational evolution of a level 
set representation. Object appearance probabilities are fused in to the objects volume for the segmentation, such that the algorithm is robust to 
outliers in the observation images. However, their system does not provide any handling of 
loop closure occurrences and the paper makes no reference to tracking integrity. In addition, the images on which their algorithm was tested 
contained only the objects to be reconstructed, with no background noise.
\fi

\iffalse
Another volumetric object reconstruction system is presented by Gupta et al \cite{Gupta2016}, using monocular multi view cues. The authors 
perform object segmentation within a graph cut framework to yield object models and perform tracking based on visual and textual cues. 
However the authors report fluctuating camera tracking quality due to the breakage of brightness constancy and specular surfaces. In addition, 
as with all other works introduced up to this point there is no loop closure ability and tracking drift is an issue.
\fi

\iffalse
Cui et al present a system to improve the reconstruction of objects using ToF(Time of Flight) sensors \cite{Cui2013}. The authors utilise a super-resolution 
representation of chunks of raw depth images to improve the level of detail in the reconstructed models. In addition, the authors present a probabilistic 
alignment framework in their reconstruction pipeline that proves to be efficacious.
\fi

\iffalse
Slavcheva et al \cite{slavcheva2016eccv} present a volumetric object reconstruction system for RGBD sensors in which pose estimates are yielded by registering pairs of 
SDF(Signed Distance Function) volumes. Unlike many of the aforementioned works, the authors do present a loop closure step, however it is 
performed offline as a post processing step. In addition, the tracking procedure of the presented work is reliant on the use of fiducial markers.
\fi

\iffalse
Panteleris et al \cite{Pantaleris2015, Panteleris2015b} present novel approaches to object reconstruction where by segmentation and reconstruction is achieved by 
tracking hand motion. However, there is no handling of loop closure events. 
\fi

\iffalse
Finally, Weise et al present an explicit, surfel based object reconstruction system \cite{Weise2009} based on objects rotating in front of a 3D 
range scanner. During reconstruction an object topology graph is constructed that is used on-line to handle loop closure cases. When a loop 
closure is detected, if there are discrepancies in the topology graph then deformations are applied to patches of the object surface. As 
such, the two misaligned ends of the surface are realigned. However, this method requires the maintaining of a topology graph with deformation 
optimisations being computed over this graph.
\fi