\subsection{Dense 3D Reconstruction}
Much 3D reconstruction work in recent years has been influenced by the seminal KinectFusion\cite{Newcombe2011} of Newcombe et al in which
RGBD data was integrated into a volumetric reporesentation \STUART{`representation'} of the scene, performing simultaneous tracking and mapping. The end result was
high quality 3D static scene models. \STUART{Look back at the related work in the BMVC paper for this. It's arguable that we may also want to mention a few papers that are not based on KinectFusion.} However KinectFusion notably suffered from tracking drift and had no capacity to handle loop closure
events.

Following KinectFusion, Neissner et al \STUART{This isn't how you spell Niessner / Nie{\ss}ner.} present another volumetric reconstruction system\cite{Niessner2013} based around the notion of
hashing regions of space in to voxel blocks. \STUART{There were various works in between these two. See the BMVC paper.} The primary contribution is the ability to scale the abilities of KinectFusion to larger
scenes. However, the contributions do not extend to the camera tracking drift and loop closure problems.

Prisacariu et al present an alternative voxel hashing based system\cite{Prisacariu2014} which provides many optimisations and an open source 
implementation. However, the limitations of\cite{Newcombe2011,Niessner2013} with regards to loop closure and tracking drift are still present. 
However, a later publication\cite{Kahler2016} from the authors of\cite{Prisacariu2014} presents a loop closure and tracking drift reduction 
solution based on the splitting of the scene in to sub scenes with pose adjustments made to tracking constraints between them. This approach 
is pertinent to this work as it inspired the multi subsection approach that we take. \STUART{Actually it's deeply pertinent, since we essentially use the code!}

\STUART{You should be mentioning other recent works in this section, e.g.\ BundleFusion, `Large-scale and drift-free surface reconstruction using online subvolume registration', etc.}

\subsection{Object Reconstruction}
\STUART{Please see your email for a PDF containing lots of other relevant references for this section.}

In addition to the larger scale dense SLAM works discussed in the previous section, there has been much work on object reconstruction and 
object-centric SLAM. Ren et al present a probabilistic object tracking and reconstruction system\cite{Ren2013} \STUART{Put the citation directly after the et al.} that, like our work, builds 
object reconstructions based on an appearance model. The presented system of Ren et al \STUART{The prose here sounds repetitive.} evolves a level set object representation for voxels that 
are on the object, as per the appearance model. However, the presented system does not have any provision for loop closure detection and 
is prone to tracking drift over time.

Kolev et al present a probabilistic 3D segmentation and surface extraction algorithm\cite{Kolev2006} based on a variational evolution of a level 
set representation. Object appearance probabilities are fused in to the objects volume for the segmentation, much like the approach taken in 
this paper, such that the algorithm is robust to outliers in the observation images. However, their system does not provide any handling of 
loop closure occurrences and the paper makes no reference to tracking integrity. In addition, the images on which their algorithm was tested 
contained only the objects to be reconstructed, with no background noise.

Another volumetric object reconstruction system is presented by Gupta et al\cite{Gupta2016}, using monocular multi view cues. The authors 
perform object segmentation within a graph cut framework to yield object models and perform tracking based on visual and textual cues. 
However the authors report fluctuating camera tracking quality due to the breakage of brightness constancy and specular surfaces. In addition, 
as with all other works introduced up to this point there is no loop closure ability and tracking drift is an issue.

Slavcheva et al present a volumetric object reconstruction system for RGBD sensors in which pose estimates are yielded by registering pairs of 
SDF(Signed Distance Function) volumes. Unlike many of the aforementioned works, the authors do present a loop closure step, however it is 
performed offline as a post processing step, as such it is unclear what the timings for this step are. \STUART{We should email Mira and ask her.}

Finally, Weise et al present an explicit, surfel based object reconstruction system\cite{Weise2009} based on objects rotating in front of a 3D 
range scanner. During reconstruction an object topology graph is constructed that is used on-line to handle loop closure cases. When a loop 
closure is detected, if there are discrepancies in the topology graph then deformations are applied locally to patches of the object surface. As 
such, the two misaligned ends of the surface are realigned. However, what is not clear is the systems ability to handle motion beyond a simple 
rotation. \STUART{Is it not clear that it has the ability, or does it not have the ability? We should avoid weasel words here.} In addition, the use of the explicit Surfel based representation makes the reconstructed models less amenable to structured  computation(such as processing by a Convolution Neural Network) than their volumetric counterparts. \STUART{Meh! -- the `surfels are bad' argument is a weak argument, because the real problem here is the pose estimation / loop closure. If you can get that to work, then you can construct whatever representation you like. The bottom line is that we need to beat these guys fair and square: we can't dodge the bullet by saying that they use a different representation.}